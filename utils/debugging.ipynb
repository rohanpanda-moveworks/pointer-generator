{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 13:57:16.969640: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-07 13:57:16.976805: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-07 13:57:16.976819: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/rohan.panda/codes/pointer-generator/utils/debugging.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bada/home/rohan.panda/codes/pointer-generator/utils/debugging.ipynb#ch0000002vscode-remote?line=2'>3</a>\u001b[0m len_bytes\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bada/home/rohan.panda/codes/pointer-generator/utils/debugging.ipynb#ch0000002vscode-remote?line=3'>4</a>\u001b[0m str_len \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m,len_bytes)[\u001b[39m0\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bada/home/rohan.panda/codes/pointer-generator/utils/debugging.ipynb#ch0000002vscode-remote?line=5'>6</a>\u001b[0m tf_ex_str \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m'\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m str_len, fread\u001b[39m.\u001b[39;49mread(str_len))[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.py  dataset.py  debugging.ipynb\t__init__.py  __pycache__  utils.py\n"
     ]
    }
   ],
   "source": [
    "!ls \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "vocab_counter = Counter()\n",
    "\n",
    "def tokenize_sent(sent):\n",
    "    tokens =  tokenizer.tokenize(sent)\n",
    "    vocab_counter.update(tokens)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "read_file = \"/home/rohan.panda/codes/ConversationQueryRewriter/data/canard/train_total.json\"\n",
    "write_file = \"/home/rohan.panda/codes/pointer-generator/data/canard/train_tokenized.json\"\n",
    "with open(read_file) as reader, open(write_file,'w') as writer:\n",
    "    for line in reader:\n",
    "        # print(line)\n",
    "        data = json.loads(line)\n",
    "        # print(data)\n",
    "        # break\n",
    "        new_inp = []\n",
    "        for inp in data['input']:\n",
    "            new_inp.append(tokenize_sent(inp))\n",
    "        data['input'] = new_inp\n",
    "        data['target'] = tokenize_sent(data['target'])\n",
    "        writer.write(json.dumps(data)+'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/canard/vocab.txt','w') as wrt:\n",
    "    for pt in vocab_counter.most_common():\n",
    "        wrt.write(f\"{pt[0]}\\t{pt[1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rohan.panda/anaconda3/envs/pg/bin:/home/rohan.panda/.vscode-server/bin/c3511e6c69bb39013c4a4b7b9566ec1ca73fc4d5/bin/remote-cli:/home/rohan.panda/anaconda3/envs/pg/bin:/home/rohan.panda/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n",
      "/home/rohan.panda/codes/pointer-generator\n"
     ]
    }
   ],
   "source": [
    "!export PATH=$PATH:\"/home/rohan.panda/codes/pointer-generator\"\n",
    "!echo $PATH\n",
    "%cd \"/home/rohan.panda/codes/pointer-generator/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 11:37:00.396162: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-08 11:37:00.400815: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-08 11:37:00.400824: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished constructing vocabulary of 20412 total words. Last word added: occupies\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from dataset import * \n",
    "\n",
    "voc = Vocab('data/canard/vocab.txt',0)\n",
    "train_data_path = \"/home/rohan.panda/codes/pointer-generator/data/canard/train_tokenized.json\"\n",
    "batcher = Batcher(voc, train_data_path,\n",
    "                               10, single_pass=True, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batcher.next_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dataset.Batch object at 0x7f83f31f3040>\n"
     ]
    }
   ],
   "source": [
    "# voc.word2idx['[SEP]']\n",
    "# voc.idx2word[0]\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3eacf960d54db120b406098e558ee34b3808e66629c08cfa956b8e58915b8fbd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
